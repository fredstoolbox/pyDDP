# pyDDP
Use PyTorch's distributed data parallel to train a simple model in a multi-GPU environment, hyper params are included in the __main__ function of the script, use `python ./Simple_DDP.py` to start it
